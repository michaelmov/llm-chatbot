services:
  backend:
    build:
      context: .
      dockerfile: backend/Dockerfile
    ports:
      - '3001:3001'
    environment:
      - NODE_ENV=production
      - PORT=3001
      - LLM_PROVIDER=${LLM_PROVIDER:-anthropic}
      - MODEL_NAME=${MODEL_NAME:-claude-3-5-sonnet-latest}
      - MODEL_TEMPERATURE=${MODEL_TEMPERATURE:-0.3}
      - MODEL_MAX_TOKENS=${MODEL_MAX_TOKENS:-4096}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - WEATHER_API_KEY=${WEATHER_API_KEY}
    healthcheck:
      test: ['CMD', 'wget', '--no-verbose', '--tries=1', '--spider', 'http://localhost:3001/health']
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 5s
    restart: unless-stopped
    networks:
      - chatbot-network

  frontend:
    build:
      context: .
      dockerfile: frontend/Dockerfile
      args:
        - NEXT_PUBLIC_WS_URL=${NEXT_PUBLIC_WS_URL:-ws://localhost:3001/ws}
    ports:
      - '3000:3000'
    environment:
      - NODE_ENV=production
    depends_on:
      backend:
        condition: service_healthy
    healthcheck:
      test: ['CMD', 'wget', '--no-verbose', '--tries=1', '--spider', 'http://localhost:3000']
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    restart: unless-stopped
    networks:
      - chatbot-network

networks:
  chatbot-network:
    driver: bridge
